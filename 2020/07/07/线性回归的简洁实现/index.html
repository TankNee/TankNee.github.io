<!doctype html>
<html lang="zh"><head><!-- hexo injector head_begin start --><style type="text/css">.douban-card-block {
    display: flex;
    justify-content: center;
    align-items: center;
    width: 100%;
    max-height: 400px;
}

.douban-card {
    display: flex;
    margin: 30px 10px;
    padding: 15px;
    border-radius: 15px;
    position: relative;
    justify-content: center;
    align-items: center;
    overflow: hidden;
    color: antiquewhite;
    text-decoration: none;
}

.douban-card:hover {
    text-decoration: none;
}

.douban-card-bgimg {
    position: absolute;
    width: 115%;
    height: 115%;
    filter: blur(15px) brightness(0.6);
    background-size: 100%;
    background-position: center;
    background-repeat: no-repeat;
}

.douban-card-img {
    position: relative;
    height: 130px;
    width: 80px;
    background-size: 100%;
    background-position: center;
    background-repeat: no-repeat;
}

.douban-card-left:hover .douban-card-img {
    filter: blur(5px) brightness(0.6);
    transform: perspective(800px) rotateX(180deg);
}

.douban-card-left .douban-card-img {
    transition: all 500ms ease;
}

.douban-card-left {
    position: relative;
    display: flex;
    flex-direction: column;
    align-items: center;
}

.douban-card-left .douban-card-status {
    height: 130px;
    width: 80px;
    text-align: center;
    font-weight: bold;
    position: absolute;
    left: 0;
    top: 30%;
    transform: rotateX(180deg);
    backface-visibility: hidden;
    transition: all 500ms ease;
}

.douban-card-left:hover .douban-card-status {
    transform: perspective(800px) rotateX(0deg);
}

.douban-card-right {
    position: relative;
    display: flex;
    flex-direction: column;
    margin-left: 12px;
    font-size: 16px;
    font-family: "Courier New", Courier, monospace;
    line-height: 1.3;
    color: antiquewhite;
}

.douban-card-item {
    margin-top: 4px;
}
</style><!-- hexo injector head_begin end --><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><script async defer data-website-id="736fdcdf-b838-4814-978f-eb419e113fdd" src="https://dashboard.tanknee.cn/umami.js"></script><script src="/freecdn-loader.min.js"></script><meta><title>线性回归的简洁实现 - 归舟棹远</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="归舟棹远"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="归舟棹远"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="线性回归个人理解是通过建立反馈机制,逐层优化筛选最优的权重参数,以达到对最佳算法的逼近.也就是通过数值解逼近解析解. 预测二手房价格"><meta property="og:type" content="blog"><meta property="og:title" content="线性回归的简洁实现"><meta property="og:url" content="https://www.tanknee.cn/2020/07/07/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/"><meta property="og:site_name" content="归舟棹远"><meta property="og:description" content="线性回归个人理解是通过建立反馈机制,逐层优化筛选最优的权重参数,以达到对最佳算法的逼近.也就是通过数值解逼近解析解. 预测二手房价格"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://img.tanknee.cn/blogpicbed/2020/07/2020070663a16a4fd6848.png"><meta property="article:published_time" content="2020-07-07T08:49:29.000Z"><meta property="article:modified_time" content="2022-06-17T08:34:10.671Z"><meta property="article:author" content="TankNee"><meta property="article:tag" content="线性回归"><meta property="article:tag" content="neural network"><meta property="article:tag" content="machine learning"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://img.tanknee.cn/blogpicbed/2020/07/2020070663a16a4fd6848.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.tanknee.cn/2020/07/07/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/"},"headline":"线性回归的简洁实现","image":["https://img.tanknee.cn/blogpicbed/2020/07/2020070663a16a4fd6848.png"],"datePublished":"2020-07-07T08:49:29.000Z","dateModified":"2022-06-17T08:34:10.671Z","author":{"@type":"Person","name":"TankNee"},"publisher":{"@type":"Organization","name":"归舟棹远","logo":{"@type":"ImageObject","url":"https://www.tanknee.cn/img/logo.svg"}},"description":"线性回归个人理解是通过建立反馈机制,逐层优化筛选最优的权重参数,以达到对最佳算法的逼近.也就是通过数值解逼近解析解. 预测二手房价格"}</script><link rel="canonical" href="https://www.tanknee.cn/2020/07/07/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.15.2/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.loli.net/ajax/libs/pace/1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="归舟棹远" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="归舟棹远" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/gallery">图库</a><a class="navbar-item" href="/links">友链</a><a class="navbar-item" href="/talk">杂言</a><a class="navbar-item" href="/message">留言</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="TankNee&#039;s GitHub" href="https://github.com/TankNee"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-07-07T08:49:29.000Z" title="2020/7/7 16:49:29">07/07/2020</time>发表</span><span class="level-item"><a class="link-muted" href="/categories/AiLearning/">AiLearning</a></span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">线性回归的简洁实现</h1><div class="content"><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>个人理解是通过建立反馈机制,逐层优化筛选最优的权重参数,以达到对最佳算法的逼近.也就是通过数值解逼近解析解.</p>
<h3 id="预测二手房价格"><a href="#预测二手房价格" class="headerlink" title="预测二手房价格"></a>预测二手房价格</h3><p>设房屋的面积为$x_1$，房龄为$x_2$，售出价格为$y$。我们需要建立基于输入$x_1$和$x_2$来计算输出$y$的表达式，也就是模型（model）。顾名思义，线性回归假设输出与各个输入之间是线性关系：</p>
<p>$$<br>\hat{y} = x_1 w_1 + x_2 w_2 + b<br>$$<br>很明显我们能看到这是一个线性表达式，其中有两个参数会影响最终的输出结果，我们要做的事情就是找出最佳的$w_1$与$w_2$来实现对$y$的预测!</p>
<h3 id="训练数据-Train-Data"><a href="#训练数据-Train-Data" class="headerlink" title="训练数据(Train Data)"></a>训练数据(Train Data)</h3><p>我们通常收集一系列的真实数据，例如多栋房屋的真实售出价格和它们对应的面积和房龄。我们希望在这个数据上面寻找模型参数来使模型的预测价格与真实价格的误差最小。在机器学习术语里，该数据集被称为训练数据集（training data set）或训练集（training set），一栋房屋被称为一个样本（sample），其真实售出价格叫作标签（label），用来预测标签的两个因素叫作特征（feature）。特征用来表征样本的特点。</p>
<p>假设我们采集的样本数为$n$，索引为$i$的样本的特征为$x_1^{(i)}$和$x_2^{(i)}$，标签为$y^{(i)}$。对于索引为$i$的房屋，线性回归模型的房屋价格预测表达式为</p>
<p>$$<br>\hat{y}^{(i)} = x_1^{(i)} w_1 + x_2^{(i)} w_2 + b.<br>$$</p>
<h3 id="损失函数-Loss-Function"><a href="#损失函数-Loss-Function" class="headerlink" title="损失函数(Loss Function)"></a>损失函数(Loss Function)</h3><p>在模型训练中，我们需要衡量价格预测值与真实值之间的误差。通常我们会选取一个非负数作为误差，且数值越小表示误差越小。一个常用的选择是平方函数。它在评估索引为$i$的样本误差的表达式为</p>
<p>$$<br>\ell^{(i)}(w_1, w_2, b) = \frac{1}{2} \left(\hat{y}^{(i)} - y^{(i)}\right)^2,<br>$$</p>
<p>其中常数$\frac{1}{2}$使对平方项求导后的常数系数为1，这样在形式上稍微简单一些。显然，误差越小表示预测价格与真实价格越相近，且当二者相等时误差为0。给定训练数据集，这个误差只与模型参数相关，因此我们将它记为以模型参数为参数的函数。在机器学习里，将衡量误差的函数称为损失函数（loss function）。这里使用的平方误差函数也称为平方损失（square loss）。</p>
<p>通常，我们用训练数据集中所有样本误差的平均来衡量模型预测的质量，即</p>
<p>$$<br>\ell(w_1, w_2, b) =\frac{1}{n} \sum_{i=1}^n \ell^{(i)}(w_1, w_2, b) =\frac{1}{n} \sum_{i=1}^n \frac{1}{2}\left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right)^2.<br>$$</p>
<p>在模型训练中，我们希望找出一组模型参数，记为 $w_1^*, w_2^*, b^*$ ，来使训练样本平均损失最小：</p>
<p>$$<br>w_1^*, w_2^*, b^* = \operatorname*{argmin}_{w_1, w_2, b}\  \ell(w_1, w_2, b).<br>$$</p>
<h3 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h3><p>当模型和损失函数形式较为简单时，上面的误差最小化问题的解可以直接用公式表达出来。这类解叫作解析解（analytical solution）。本节使用的线性回归和平方误差刚好属于这个范畴。然而，大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫作数值解（numerical solution）。</p>
<p>在求数值解的优化算法中，小批量随机梯度下降（mini-batch stochastic gradient descent）在深度学习中被广泛使用。它的算法很简单：先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch）$\mathcal{B}$，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后用此结果与预先设定的一个正数的乘积作为模型参数在本次迭代的减小量。</p>
<p>在训练本节讨论的线性回归模型的过程中，模型的每个参数将作如下迭代：</p>
<p>$$<br>\begin{aligned}<br>w_1 &amp;\leftarrow w_1 -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \frac{ \partial \ell^{(i)}(w_1, w_2, b)  }{\partial w_1} = w_1 -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}x_1^{(i)} \left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right),\\<br>w_2 &amp;\leftarrow w_2 -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \frac{ \partial \ell^{(i)}(w_1, w_2, b)  }{\partial w_2} = w_2 -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}x_2^{(i)} \left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right),\\<br>b &amp;\leftarrow b -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \frac{ \partial \ell^{(i)}(w_1, w_2, b)  }{\partial b} = b -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}\left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right).<br>\end{aligned}<br>$$<br>迭代以获取最优的参数</p>
<h3 id="数据归一化和标准化"><a href="#数据归一化和标准化" class="headerlink" title="数据归一化和标准化"></a>数据归一化和标准化</h3><p>不同数值的差异对结果的影响是完全不同的.例如身高从1.6到1.8那么他的体重可能就会从50到100,可见身高变化的幅度相对体重要小得多,也就是说体重拥有更好的非线性决断能力!</p>
<p>因此我们需要通过归一化与标准化,让我们所有的特征值都统一到一个标准的区间!</p>
<h3 id="线性函数归一化"><a href="#线性函数归一化" class="headerlink" title="线性函数归一化"></a>线性函数归一化</h3><p>$$<br>X_{normal}=\frac{X-X_{min}}{X_{max}-X{min}}<br>$$</p>
<ul>
<li>$X$原始特征数据</li>
<li>$X_{min},X_{max}$所有样本中的最小值与最大值</li>
<li>$X_{normal}$归一化之后的数据,在$[0,1]$之间</li>
</ul>
<h3 id="零均值标准化"><a href="#零均值标准化" class="headerlink" title="零均值标准化"></a>零均值标准化</h3><p>$$<br>X_{normal}=\frac{X-\mu}{\sigma}<br>$$</p>
<ul>
<li>$\mu$均值</li>
<li>$\sigma$标准差,一般设为1</li>
<li>$X_{normal}$归一化之后的数据</li>
</ul>
<hr>
<h2 id="数学基础附录"><a href="#数学基础附录" class="headerlink" title="数学基础附录"></a>数学基础附录</h2><h3 id="满秩的概念"><a href="#满秩的概念" class="headerlink" title="满秩的概念"></a>满秩的概念</h3><h4 id="定义一"><a href="#定义一" class="headerlink" title="定义一"></a>定义一</h4><p>使用初等行变化将矩阵化简为阶梯型矩阵,则矩阵中非零行的个数就是该矩阵的秩。</p>
<p>当矩阵的秩等于矩阵的行数时，就称该矩阵为满秩矩阵。</p>
<h4 id="定义二"><a href="#定义二" class="headerlink" title="定义二"></a>定义二</h4><p>若该矩阵的某一<code>r</code>阶子式的行列式不为零,并且所有大于<code>r</code>阶的子式的行列式全为0,那么就称该矩阵的秩为<code>r</code>,使用符号记为:<br>$$<br>A_{m*n}:R(A)=r<br>$$<br>如果有以下的等式<br>$$<br>R(A)=m<br>$$</p>
<p>$$<br>R(A)=n<br>$$</p>
<p>那就称之为行满秩矩阵或者是列满秩矩阵!</p>
<p>若有$m=n$则称之为满秩矩阵,可逆矩阵,非奇异矩阵.</p>
<h3 id="似然函数"><a href="#似然函数" class="headerlink" title="似然函数"></a>似然函数</h3><p>对于函数$p=(x|\theta)$而言,如果我们将$\theta$设为常量,那么我们将得到一个关于$x$的函数,也就是关于$x$的概率分布.</p>
<p>而当我们将$\theta$当作变量,将$x$当作常量时,我们就得到了关于$\theta$的极大似然函数!</p>
<p>对于极大似然函数,我们可以给出一个简单的示例:</p>
<p>对一枚硬币随机抛掷十次,得到一个结果组:$x=HHTTHTHHHH$,也就是一组正反序列,很显然,对于抛掷硬币的实验,其分布是一组二项分布,不是正面就是反面,那么我们可以很简单的得到一个表达式:$x=\theta^7(1-\theta)^3$,对于$\theta$的不同取值,表达式也会有不同的结果,但其变量是在$[0,1]$上的,所以我们可以取遍其所有的值,获得一张表:</p>
<p><img src="https://img.tanknee.cn/blogpicbed/2020/07/2020070663a16a4fd6848.png" alt="image-20200706110107376"></p>
<p>可以看到在0.7时取到最大值,也就是最大似然估计值.显然,由于样本数过少,这个值是不太可能的一个值.</p>
<p>所有我们可以认为,这个等式的核心意思都是在给一个theta和一个样本x的时候，整个事件发生的可能性多大</p>
<h3 id="贝叶斯公式-Bayes’-theorem"><a href="#贝叶斯公式-Bayes’-theorem" class="headerlink" title="贝叶斯公式(Bayes’ theorem)"></a>贝叶斯公式(Bayes’ theorem)</h3><p>$$<br>P(A|B)=\frac{P(A)P(B|A)}{P(B)}<br>$$</p>
<h3 id="凹函数与凸函数"><a href="#凹函数与凸函数" class="headerlink" title="凹函数与凸函数"></a>凹函数与凸函数</h3><h4 id="凸函数"><a href="#凸函数" class="headerlink" title="凸函数"></a>凸函数</h4><p>$$<br>f(\frac{x_1+x_2}{2})&gt;\frac{f(x_1)+f(x_2)}{2}<br>$$</p>
<p>上面是一个特殊的定义,更加一般的定义是:<br>$$<br>f(ax_1+bx_2)&gt;af(x_1)+bf(x_2)。    a+b=1<br>$$<br>那么凹函数也就是凸函数取反，即可得到。</p>
<h4 id="凹函数"><a href="#凹函数" class="headerlink" title="凹函数"></a>凹函数</h4><p>$$<br>f(ax_1+bx_2)&lt;af(x_1)+bf(x_2)。    a+b=1<br>$$</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>线性回归的简洁实现</p><p><a href="https://www.tanknee.cn/2020/07/07/线性回归的简洁实现/">https://www.tanknee.cn/2020/07/07/线性回归的简洁实现/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>TankNee</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>07/07/2020</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>06/17/2022</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">线性回归</a><a class="link-muted mr-2" rel="tag" href="/tags/neural-network/">neural network</a><a class="link-muted mr-2" rel="tag" href="/tags/machine-learning/">machine learning</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://img.tanknee.cn/profile/AliPay.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://img.tanknee.cn/profile/wechatPay.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/07/08/Hexo%E8%B1%86%E7%93%A3%E6%96%87%E7%AB%A0%E6%8F%92%E4%BB%B6/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Hexo豆瓣文章插件</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/06/06/aliyunAiDayThree/"><span class="level-item">阿里云Ai训练营DayThree</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="content" id="valine-thread"></div><script src="//cdn.jsdelivr.net/npm/leancloud-storage@3/dist/av-min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/valine/1.4.16/Valine.min.js"></script><script>new Valine({
            el: '#valine-thread',
            appId: "tJv0hJ0qmpEgSvlqwrqQbBL9-gzGzoHsz",
            appKey: "YQyMpfNKSaHjrlBu3kMjwAo1",
            placeholder: "留言清风过，抚菁杂草生。",
            avatar: "mm",
            avatarForce: false,
            meta: ["nick","mail","link"],
            pageSize: 10,
            lang: "zh-CN",
            visitor: false,
            highlight: true,
            recordIP: true,
            
            
            
            enableQQ: true,
            requiredFields: [],
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#线性回归"><span class="level-left"><span class="level-item">1</span><span class="level-item">线性回归</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#预测二手房价格"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">预测二手房价格</span></span></a></li><li><a class="level is-mobile" href="#训练数据-Train-Data"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">训练数据(Train Data)</span></span></a></li><li><a class="level is-mobile" href="#损失函数-Loss-Function"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">损失函数(Loss Function)</span></span></a></li><li><a class="level is-mobile" href="#优化算法"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">优化算法</span></span></a></li><li><a class="level is-mobile" href="#数据归一化和标准化"><span class="level-left"><span class="level-item">1.5</span><span class="level-item">数据归一化和标准化</span></span></a></li><li><a class="level is-mobile" href="#线性函数归一化"><span class="level-left"><span class="level-item">1.6</span><span class="level-item">线性函数归一化</span></span></a></li><li><a class="level is-mobile" href="#零均值标准化"><span class="level-left"><span class="level-item">1.7</span><span class="level-item">零均值标准化</span></span></a></li></ul></li><li><a class="level is-mobile" href="#数学基础附录"><span class="level-left"><span class="level-item">2</span><span class="level-item">数学基础附录</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#满秩的概念"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">满秩的概念</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#定义一"><span class="level-left"><span class="level-item">2.1.1</span><span class="level-item">定义一</span></span></a></li><li><a class="level is-mobile" href="#定义二"><span class="level-left"><span class="level-item">2.1.2</span><span class="level-item">定义二</span></span></a></li></ul></li><li><a class="level is-mobile" href="#似然函数"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">似然函数</span></span></a></li><li><a class="level is-mobile" href="#贝叶斯公式-Bayes’-theorem"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">贝叶斯公式(Bayes’ theorem)</span></span></a></li><li><a class="level is-mobile" href="#凹函数与凸函数"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">凹函数与凸函数</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#凸函数"><span class="level-left"><span class="level-item">2.4.1</span><span class="level-item">凸函数</span></span></a></li><li><a class="level is-mobile" href="#凹函数"><span class="level-left"><span class="level-item">2.4.2</span><span class="level-item">凹函数</span></span></a></li></ul></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2022/07/29/Nodejs-%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%BA%93-HTTP-307-%E9%87%8D%E5%AE%9A%E5%90%91%E9%97%AE%E9%A2%98/"><img src="https://img.tanknee.cn/blogpicbed/2022/07/29/22072962e3d33fc90bb.png/webp" alt="Nodejs 网络请求库 HTTP 307 重定向问题"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-07-29T03:31:14.000Z">07/29/2022</time></p><p class="title"><a href="/2022/07/29/Nodejs-%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%BA%93-HTTP-307-%E9%87%8D%E5%AE%9A%E5%90%91%E9%97%AE%E9%A2%98/">Nodejs 网络请求库 HTTP 307 重定向问题</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2022/07/13/%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E4%B8%8D%E7%9B%B8%E5%85%B3%E7%9A%84GIT%E4%BB%93%E5%BA%93/"><img src="https://img.tanknee.cn/blogpicbed/2022/07/13/22071362cec05c4522c.png/webp" alt="合并两个不相关的GIT仓库"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-07-13T12:45:14.000Z">07/13/2022</time></p><p class="title"><a href="/2022/07/13/%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E4%B8%8D%E7%9B%B8%E5%85%B3%E7%9A%84GIT%E4%BB%93%E5%BA%93/">合并两个不相关的GIT仓库</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2022/06/18/%E6%9D%A5%E5%88%9B%E9%80%A0%E4%B8%80%E4%B8%AA%E5%8C%BF%E5%90%8D%E6%8F%90%E9%97%AE%E7%AE%B1%E5%90%A7/"><img src="https://img.tanknee.cn/blogpicbed/2022/06/18/22061862ad359de99a1.webp" alt="来创造一个匿名提问箱吧"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-06-18T02:33:45.000Z">06/18/2022</time></p><p class="title"><a href="/2022/06/18/%E6%9D%A5%E5%88%9B%E9%80%A0%E4%B8%80%E4%B8%AA%E5%8C%BF%E5%90%8D%E6%8F%90%E9%97%AE%E7%AE%B1%E5%90%A7/">来创造一个匿名提问箱吧</a></p><p class="categories"><a href="/categories/Code/">Code</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-07-08T10:12:42.000Z">07/08/2020</time></p><p class="title"><a href="/2020/07/08/Hexo%E8%B1%86%E7%93%A3%E6%96%87%E7%AB%A0%E6%8F%92%E4%BB%B6/">Hexo豆瓣文章插件</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-07-07T08:49:29.000Z">07/07/2020</time></p><p class="title"><a href="/2020/07/07/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/">线性回归的简洁实现</a></p><p class="categories"><a href="/categories/AiLearning/">AiLearning</a></p></div></article></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AiLearning/"><span class="level-start"><span class="level-item">AiLearning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Code/"><span class="level-start"><span class="level-item">Code</span></span><span class="level-end"><span class="level-item tag">35</span></span></a></li></ul></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="归舟棹远" height="28"></a><p class="is-size-7"><span>&copy; 2022 TankNee</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="TankNee&#039;s GitHub" href="https://github.com/TankNee"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>